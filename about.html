---
layout: page
title: About
og-description: Arkose's strategic advisors, experts, and team
nav-menu: true
order: 2
---


<div class="section">
  <div class="inner">
    <div class="row align-items-center">
      <div>
        <h1> About </h1>
        <p>Arkose was a field-building nonprofit that closed in June of 2025. Arkose focused on supporting researchers, engineers, and other professionals interested in contributing to AI safety. This website is an archival version of Arkose's resources; some areas may be out of date.</p>
        <!-- Arkose is a nonprofit with the mission of improving the safety of advanced AI systems, focused on reducing potential large-scale risks. -->
      </div>
    </div>
  </div>
</div>

{% if false %}
<!-- {% assign cards = site.advisors %}
{% assign advisors1 = cards | where: "section", "strategic" | sort: 'order' %}
{% assign advisors2 = cards | where: "section", "selected" | sort: 'order' %}

<div class="section bg-gray" id="experts">
  <div class="inner">

    <h2>Selected Experts</h2>

    <p>Experts generously lend their knowledge and time to Arkose's pairing program, providing one-on-one support to researchers and engineers interested in contributing to technical AI safety.</p>

    <div class="cards">
      {% for card in advisors2 %}
        {% include person_card.html card=card %}
      {% endfor %}
    </div>
  </div>
</div>


<div class="section" id="panel">
  <div class="inner">
    <h2>Strategic Advisory Panel</h2>

    <p>Strategic advisory panel members advise on Arkose's suggested resources, recommendations, and strategic direction.</p>

    <div class="cards">
      {% for card in advisors1 %}
        {% include person_card.html card=card %}
      {% endfor %}
    </div>
  </div>
</div> -->
{% endif %}

<div class="section bg-gray">
  <div class="inner">
    <h2>Team</h2>
    <div class="cards">
      <a href="/victoria-brook">
        <div class="card card-team">
          <div class="card-thumbnail">
            <img src="/assets/images/people/victoria-brook.jpg">
          </div>
          <div class="card-content">
            <div class="card-title">
              <h3>Victoria Brook</h3>
            </div>
            <div class="card-description">Executive Director</div>
          </div>
        </div>
      </a>
      <a href="https://www.linkedin.com/in/marissala/">
        <div class="card card-team">
          <div class="card-thumbnail">
            <img src="/assets/images/people/maris-sala.jpg">
          </div>
          <div class="card-content">
            <div class="card-title">
              <h3>Maris Sala</h3>
            </div>
            <div class="card-description">Operations Lead</div>
          </div>
        </div>
      </a>
      <a href="https://vaelgates.com">
        <div class="card card-team">
          <div class="card-thumbnail">
            <img src="/assets/images/people/vael-gates.jpg">
          </div>
          <div class="card-content">
            <div class="card-title">
              <h3>Dr. Vael Gates</h3>
            </div>
            <div class="card-description">Advisor (Founder)</div>
          </div>
        </div>
      </a>
    </div>
  </div>
</div>

<section>
  <div class="inner">
    <h2><i>Previous Work</i></h2>
    <h2 id="ai_risk_discussions">AI Risk Discussions</h2>
    <p>Arkose's older 2022 work aimed to facilitate discussion and evaluation of potential risks from advanced AI, with a focus on soliciting and engaging with expert perspectives on the arguments and providing resources for stakeholders. Our results, based on a set of 97 interviews with AI researchers on their perspectives on current AI and the future of AI (pre-ChatGPT era), can be found below.</p>
    <br>
    <div class="row">
      <div class="6u 12u$(small)">
        <a href="interviews.html" class="button fit">Interviews</a>
        <p>One of our main goals was to facilitate conversations between those concerned about potential risks from advanced AI systems and technical experts. To that end, we conducted 97 interviews with AI researchers on their perspectives on current AI and the future of AI, with a focus on risks from advanced systems. This collection of interviews includes anonymized transcripts, quantitative analysis of the most common perspectives, and an academic talk discussing preliminary findings.</p>
      </div>
      <div class="6u$ 12u$(small)">
        <a href="{{site.baseurl}}{% link perspectives/introduction.html %}" class="button fit">Interactive Walkthrough</a>
        <p>In our interviews with AI researchers, some of the core questions focused on risks from advanced AI systems. To explore the interview questions, common responses from AI researchers, and potential counterarguments, we created an interactive walkthrough. You are encouraged to explore your own perspectives, and at the conclusion your series of agreements or disagreements will be displayed, so that you can compare your perspectives to other users' of the site.</p> 
      </div>
    </div>
    <h4>Project contributors</h4>
    <div id="about_us" class="text-smaller">
      <p>AI Risk Discussions was led by Dr. Vael Gates, with many other contributors, most prominently Lukas Trötzmüller (interactive walkthrough), Maheen Shermohammed (quantitative analysis), Zi Cheng (Sam) Huang (interview tagging), and Michael Keenan (website development).</p>
    </div>
  </div>
</section>

