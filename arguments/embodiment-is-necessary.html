---
layout: argument
title: "We need embodiment"
breadcrumbs: Generally Capable AI:when-generally-capable-ai,Never:never,We need embodiment:embodiment-is-necessary
---

<blockquote><p>
 It's going to be extremely difficult to develop something that is sufficiently reliable and has an understanding of the world that is sufficiently grounded in the actual world without doing some kind of mimicking of human experiential learning. So I'm thinking: reinforcement learning in robots that actually move around the world. I think without something like that, it's going to be extremely difficult to tether the knowledge and the symbolic manipulation power that the AIs have to the actual contents of the world. 
</p></blockquote>

<p>Even if it is necessary for a robot to have sensory data in order to achieve AGI, this should not pose a significant obstacle in the long run. If it’s necessary, someone will create it sooner or later. If a large number of sensors and various types of real-world data are required (beyond just a single robot), that is feasible as well.</p>
<p>Suppose the robot needs a 20-year training process to “grow up,” like a child. That would not be an obstacle either, and the robot could potentially perform this training faster than a human:</p>
<ul><li>The robot wouldn't need to sleep or do many of the other things a human must do.</li>
<li>Human children do many things to learn that require only their mind and don’t involve embodiment—for example, watching movies and reading books. These tasks could be greatly sped up.</li>
<li>If this is actually the path towards AGI, then we’d just need to do the training process once—after that, the result could be copied indefinitely. This may be a costly and difficult process, but there’s no reason to think it would be impossible.</li>
</ul><p>Furthermore, it is not clear that “embodiment” means the AI has to interact with the real world. One could place a simulated body in a 3D environment that contains simulacra of real-world phenomena like human actors and physical processes. This would have benefits over training in the real world:</p>
<ul><li>Training environments could be tested until one is found that works even better than the real world.</li>
<li>Computer graphics and physics simulation are mature technologies, and can be greatly accelerated compared to real life.</li>
</ul><p>Robotics AI might be lagging behind language AI, but there’s no reason to think it may not catch up in a decade or two. This would be a delay before AGI, but not an insurmountable obstacle.</p>
<p>Consider <a href='https://openai.com/blog/vpt/' target='_blank'>Video PreTraining (OpenAI, 2022)</a>:</p>
<ul><li>The researchers created a system able to play Minecraft on a high level.</li>
<li>In this research, the AI never actually interacted with the game during training, which means this training method had nothing resembling embodiment. Despite this, the AI learned to perform complex actions—just by watching.</li>
<li>Sidenote: A small amount of the training data was labeled (meaning: screen recordings accompanied by keystroke and mouse data). However, most of the training data consisted of unlabeled video.</li>
</ul><p>Many complex cognitive tasks can be solved using language training only—not even using other types of data, and certainly no embodiment. Many capabilities have been unlocked just in the past two years by large language models like GPT-3 and PaLM. There is reason to suspect we have not reached the limits of language-based AI.</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
