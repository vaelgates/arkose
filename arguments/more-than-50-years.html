---
layout: argument
title: "More than 50 years"
breadcrumbs: Generally capable AI systems:when-agi,More than 50 years:more-than-50-years
---
<div><blockquote>. I think we're still a solid century behind that. Yeah, I don't know. I just feel like it's still a solid century behind because that might require a huge paradigm shift in how we're training our models.  (extraN_lgu5f_Sam (I think they changed their mind), Pos. 14)</div>
<div>I guess at least 50 years. Because, yeah, I think there is some level of strong intelligence, we can achieve within 50 years, but  for fully automated intelligence I guess at least 50 years. (fs7q1_Sam, Pos. 10)</div>
<div>I think current deep learning may face some problems. I'm not thinking that we can continue this way or that deep learning is the final solution to general artificial intelligence. But I think in maybe 50 years or longer we can achieve such a level of human intelligence. (ksw4e_Sam, Pos. 13)</div>
<div></blockquote></div>
<div>It is difficult to predict any new technology. That said, there are reasons to think that there is some chance that general artificial intelligence will be developed within the next 50 years.</div>
<div>Would you like to hear these arguments, or would you like to move on and learn about arguments for potential risk from AI?</div>
<div><a href='/arguments/agisooner.html'>Yes, I would like to hear these arguments for why AGI might come soon</a></div>
<div><a href='/arguments/goto-potential-risk.html'>No, letâ€™s move on - I want to learn about arguments for potential risk from AI</a></div>
