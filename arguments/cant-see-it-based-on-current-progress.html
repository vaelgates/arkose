---
layout: argument
title: "Can’t see it based on current progress"
breadcrumbs: Generally capable AI systems:when-agi,Never:never,Can’t see it based on current progress:cant-see-it-based-on-current-progress
---

<blockquote>

<div>0:23:46.0 Interviewee: In answering your question, I don't think it will necessarily diverge, we'll just hit a roadblock and we're already hitting them. You've heard about AlexNet like 10 years ago, and now, sure, we have cute applications and like filters on the phone, but like, did AI actually enter your life, daily life? Well, not true, I mean, you have a better phone, they're more capable, but actually AI, like in terms of that we all dream about, does it enter your life? Well, not really. We can live without it, right? So, we're already hitting all these roadblocks, even in medical applications.10 years ago Google claimed they'd solved like  skin cancer, when they can detect it, and it didn't... It didn't really see the light of day except for some hospitals in India, unfortunately. So we're already hitting tons of roadblocks, and I don't think it's... It's like for this reason precisely, because when you face reality, you just don't work as good as you expect for multiple reasons. </div>
[Interviewer: “I We have been working on AI for under 100 years, and we are on an exponential trend in terms of human technological development. 10,000 years ago, not much changed from lifetime to lifetime, and now things change extremely quickly.”] I would challenge your exponential argument. I agree that a lot of things in our world are exponential, but progress in many fields hasn't been. But I guess what I was going to say is like for example, life expectancy hasn't been growing. You could have looked at that and it was flat and then it blew up, I don't know, early 1900s maybe. But it's plateaued. You could look at Moore's Law, it's starting to die. I think all those arguments pre-suppose that this sort of exponential growth continues and I don't know if I agree with that baseline assumption. Yeah, I guess, I think the logic that all of us have is like, "Yeah, we will continue to have faster computers, we'll continue to have newer technologies." But I just don't know if that's true. Yeah, [person] often says all these things, it's like 50 years until infinity, that's the range, and I think that's true. It could be anywhere there. It's hard to put a number to it. And yeah, I don't know. Again, I just challenge the assumption of the base. I just don't see, for example, like computing power continuing to grow. There's fundamental limits to it, both in the quantum side and the classical side. 

</blockquote>

<div>Obviously, current systems are not generally intelligent. However, they do display capabilities that are quite remarkable given that they are not AGI yet:</div>

<ul><li>PaLM (2022) was the most compute intensive model ever trained at the time of release [ https://ourworldindata.org/grapher/ai-training-computation?time=2017-08-04..2022-07-01 ]. It achieved state-of-the-art few-shot performance across numerous difficult NLP tasks, including natural language inference, common-sense reasoning, in-context reading comprehension and question answering. The system is also able to explain novel jokes.</li>
</ul><div><figure><img src='{{site.baseurl}}{% link assets/images/arguments/9A36C1759D7EA7B70A424A7E6D4EDA0A.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>PaLM capabilities gain as a function of model size - note that new capabilities suddenly appear as the model grows
</figcaption></figure></div>
<div><figure><img src='{{site.baseurl}}{% link assets/images/arguments/22C55F4C3CFD67F74FEC6CA19DB7F56E.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>Explaining Jokes using PaLM (2-shot) [https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf] 
</figcaption></figure></div>
<ul><li>The interesting thing here is that scaling alone, without adding new insights, creates qualitative differences in abilities. PaLM gained these abilities (like explaining jokes and answering physics questions) without anyone having properly understood how the human brain does them.</li>
</ul><li>Dall-E 2, which shows creativity and the ability to understand concepts</li>
<li><figure><img src='{{site.baseurl}}{% link assets/images/arguments/3D83536B320986F415E1552745DEBFA6.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>Dall-E 2 samples, source: <a href='https://cdn.openai.com/papers/dall-e-2.pdf' target='_blank'>OpenAI</a> 
</figcaption></figure></li>
<li>A 2021 paper from Deepmind engaging in a variety of tasks in a virtual environment, and then generalising to novel games never seen in training [ https://www.deepmind.com/blog/generally-capable-agents-emerge-from-open-ended-play ]</li>

<div>Even if we have not achieved AGI yet, it is quite plausible that we could get there eventually:</div>

<ol><li>History of people being wrong about what’s impossible</li>
<ol><li>Consider, for example, that just two years before the first flight of the Wright Brothers, Wilbur Wright himself predicted it was at least fifty years away (by his own account).</li>
<li>In 1933, Ernest Rutherford declared that the idea of harnessing atomic energy was “moonshine”. Shortly thereafter (the very next day, according to some accounts) Leo Szilard discovered the possibility of a chain reaction.<br/>In 1939, Enrico Fermi proclaimed that the chain reaction was just a “remote possibility” - four years later, he himself oversaw the world’s first nuclear reactor.</li>
<li>In an informal review, <a href='https://www.cold-takes.com/the-track-record-of-futurists-seems-fine/' target='_blank'>predictions of the “Big Three” science fiction writers</a> of the 20th century were categorized and evaluated - at least 31% of their predictions turned out to be correct.</li>
</ol><li>Ridiculous amount of progress made so far, which people were wrong about, since deep learning revolution</li>
<li>Lots of investment in this, time, money, people, with international economic interests and massive increases in investment <a href='https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/' target='_blank'>since 2010</a></li>
<li>Evolution got there in a pretty “dumb” way: Intelligence arose as a side effect of biological agents roaming in a complex environment and competing for fitness advantage.</li>
</ol>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
