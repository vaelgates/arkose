---
layout: argument
title: "I can’t see it based on current progress"
breadcrumbs: When will we get generally capable AI systems?:when-agi,Never:never,I can’t see it based on current progress:i-can’t-see-it-based-on-current-progress
---
<div><blockquote></div>
<div>0:23:46.0 Interviewee: In answering your question, I don't think it will necessarily diverge, we'll just hit a roadblock and we're already hitting them. You've heard about AlexNet like 10 years ago, and now, sure, we have cute applications and like filters on the phone, but like, did AI actually enter your life, daily life? Well, not true, I mean, you have a better phone, they're more capable, but actually AI, like in terms of that we all dream about, does it enter your life? Well, not really. We can live without it, right? So, we're already hitting all these roadblocks, even in medical applications.10 years ago Google claimed they'd solved like  skin cancer, when they can detect it, and it didn't... It didn't really see the light of day except for some hospitals in India, unfortunately. So we're already hitting tons of roadblocks, and I don't think it's... It's like for this reason precisely, because when you face reality, you just don't work as good as you expect for multiple reasons. (extraN_q243b_Sam, Pos. 45)</div>
<div>I would challenge your exponential argument. I agree that a lot of things in our world are exponential, but progress in many fields hasn't been. But I guess what I was going to say is like for example, life expectancy hasn't been growing. You could have looked at that and it was flat and then it blew up, I don't know, early 1900s maybe. But it's plateaued. You could look at Moore's Law, it's starting to die. I think all those arguments pre-suppose that this sort of exponential growth continues and I don't know if I agree with that baseline assumption. Yeah, I guess, I think the logic that all of us have is like, "Yeah, we will continue to have faster computers, we'll continue to have newer technologies." But I just don't know if that's true. Yeah, [person] often says all these things, it's like 50 years until infinity, that's the range, and I think that's true. It could be anywhere there. It's hard to put a number to it. And yeah, I don't know. Again, I just challenge the assumption of the base. I just don't see, for example, like computing power continuing to grow. There's fundamental limits to it, both in the quantum side and the classical side. (t8fld_Sam, Pos. 10)</div>
<div></blockquote></div>
<div>Obviously, current systems are not generally intelligent. However, they do display capabilities that are quite remarkable given that they are not AGI yet:</div>

<ul><li>PaLM (2022) was the most compute intensive model ever trained at the time of release [ https://ourworldindata.org/grapher/ai-training-computation?time=2017-08-04..2022-07-01 ]. It achieved state-of-the-art few-shot performance across numerous difficult NLP tasks, including natural language inference, common-sense reasoning, in-context reading comprehension and question answering. The system is also able to explain novel jokes.</li>
</ul><figure><img src='{% link assets/images/arguments/9A36C1759D7EA7B70A424A7E6D4EDA0A.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>PaLM capabilities gain as a function of model size - note that new capabilities suddenly appear as the model grows
</figcaption></figure>
<figure><img src='{% link assets/images/arguments/22C55F4C3CFD67F74FEC6CA19DB7F56E.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>Explaining Jokes using PaLM (2-shot) [https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf] 
</figcaption></figure>
<ul><li>The interesting thing here is that scaling alone, without adding new insights, creates qualitative differences in abilities. PaLM gained these abilities (like explaining jokes and answering physics questions) without anyone having properly understood how the human brain does them.</li>
</ul><li>Dall-E 2, which shows creativity and the ability to understand concepts</li>
<figure><img src='{% link assets/images/arguments/3D83536B320986F415E1552745DEBFA6.png %}' referrerpolicy='no-referrer'/><figcaption markdown='1'>Dall-E 2 samples, source: <a href='https://cdn.openai.com/papers/dall-e-2.pdf'>OpenAI</a> 
</figcaption></figure>
<li>A 2021 paper from Deepmind engaging in a variety of tasks in a virtual environment, and then generalising to novel games never seen in training [ https://www.deepmind.com/blog/generally-capable-agents-emerge-from-open-ended-play ]</li>
<li>TODO: show Imagen examples here, to hit the point home even more how quickly the progress has been in just 1 year</li>

