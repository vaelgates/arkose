---
layout: argument
title: "Misuse is a bigger problem"
breadcrumbs: The Alignment Problem:the-alignment-problem,Misuse is a bigger problem:misuse-is-a-bigger-problem
---

<blockquote>
I guess like anything I see, there is a risk, just like any other tool, that this will be used for nefarious purposes, like automated systems that make decisions in a way that we don't quite understand. Then baking in of bias, whether we're talking about automated weapon systems that make decisions on closing the loop in deciding who to shoot to automated decisions and policing and things like that. 
</blockquote>

<ul><li>Misuse continues to be a problem as we get more and more powerful systems. For example, i A great example of this is nuclear weapons: I t used to be impossible for a small number of people to cause incredible damage. But now that we’ve developed nuclear weapons, whoever is in control of those weapons has a huge amount of power to affect the world in a way that wasn’t true historically.</li>
<ul><li>You might argue that AI is similar, in that a small number of actors may have an outsized ability to affect the world . This is because the development of cutting-edge AI is currently happening at just a small number of well-funded companies. These companies will then have outsized power.</li>
<li>Alternatively, if it turns out that AGI is developed in a decentralized fashion, this will create misuse problems of its own , such as a “race to the bottom” where outcomes are determined by the most immoral, misinformed, or mentally ill group or individual to control an AGI .</li>
</ul><li>H At least h umanity has dealt with misuse before. Misuse of technology Technological misuse has produced very undesirable outcomes been very bad in the past when leaders have directed an outsized amount of resources, and much attention should be focused on this.</li>
<li>But we also want to pay attention to a more neglected risk that could potentially be even worse than misuse. The thing that we’re creating ( AGI ) takes an aspect of humanity that has enabled us to shape most of our environment and become earth’s dominant species - intelligence - and amplifies it amps that up beyond human capabilities. This makes Which means that the danger from misaligned AGI superintelligent AI potentially could be significantly higher than the danger from previous misuses of technology.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
