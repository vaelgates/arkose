---
layout: home
title: Home
landing-title: 'AI Risk Discussions'
description: null
image: null
author: null
show_tile: false
---

<div class="row">
	<div class="6u 12u$(small)">
		<a href="interviews.html" class="button fit">Interviews</a>
		<p>One of our main goals is to facilitate conversations between those concerned about potential risks from advanced AI systems and technical experts. To that end, we conducted 97 interviews with AI researchers on their perspectives on current AI and the future of AI, with a focus on risks from advanced systems. This collection of interviews includes anonymized transcripts, quantitative analysis of the most common perspectives, and an academic talk discussing preliminary findings.</p>
	</div>
	<div class="6u$ 12u$(small)">
		<a href="{{site.baseurl}}{% link arguments/introduction.html %}" class="button fit">Interactive Guide</a>
		<p>In our interviews with AI researchers, some of the core questions focused on risks from advanced AI systems. To explore the interview questions, common responses from AI researchers, and potential counterarguments, we created an interactive guide. As you agree or disagree with various arguments, these answers are logged and display at the end, alongside others' responses.</p> 
	</div>
</div>

<hr>
<h3><a href="resources.html">Resources</a> and <a href="what_can_i_do.html">Getting Involved</a></h3> 

<!-- <span class="image right"><img src="{% link assets/images/hans-peter-gauster-3y1zF4hIPCg-unsplash.jpg %}" alt="" /></span> -->

<p>Interested in learning more? Our <a href="resources.html">Resources</a> page has further reading, both for ML researchers as well as for the general public.</p>

<p>Concerned about potential risks from advanced AI systems? We have recommendations for <a href="what_can_i_do.html">what you can do to help</a>. In particular, work in technical research on AI alignment is especially needed, and we would be happy to <a href="mailto:{{site.email}}">talk with you about these opportunities</a>.</p>

<hr> 

<h4>About Us</h4>
<div id="about_us" style='font-size: 18px'>
<p>AI Risk Discussions (AIRD) was developed by Larchwood, a project of Players Philanthropy Fund, a Maryland
charitable trust recognized by IRS as a tax-exempt public charity under Section 501(c)(3)
of the Internal Revenue Code (Federal Tax ID: 27-6601178). AI Risk Discussions aims to facilitate discussion and evaluation of the risks from advanced AI. Our current focus is on soliciting expert evaluation of the arguments, understanding researcher perspectives via one-on-one conversations, and providing resources for interested stakeholders. This project is led by Dr. <a href="https://vaelgates.com">Vael Gates</a>, with many other contributors, most prominently Zi Cheng Huang (interview coding and tagging), Lukas Trötzmüller (interactive guide) and Maheen Shermohammed (quantitative analysis).</p>
</div>
