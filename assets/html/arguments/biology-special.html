<div class="page-data" data-page-title="Biology is special"></div>
<blockquote>
Interviewer: Interesting Cool, but do you think we can do it on a digital substrate? Do you think we can get something that is as capable and as intelligent and has these cognitive capacities as good as humans. Currently, humans run on wetware, we run on neurons, which fire yes or no, but can we do that same sort of thing on chips?
Interviewee: I don't think so, no. Because what we model we don't explicitly model the same way it happens in our brain, right, it's all still approximation, and we still don't know for sure how it all happens in our brain, so I think we're still missing many details from it. 
</blockquote>

<p>Consider that current AI systems can do things that would have seemed magical just a few years ago. For example:</p>
<p><figure><img src='/aird/assets/images/arguments/AEF3DE56603309886155530EA395EE38.png' referrerpolicy='no-referrer'/><figcaption markdown='1'>Image generated byDALL&#183;E 2(2021) based on the text prompt “teddy bears shopping for groceries in ancient Egypt”. The system generates images based on text prompts while exhibiting what could be reasonably described as “true creativity”
</figcaption></figure></p>
<p>GPT-3 (2020) is able to write convincing articles, generate code based on natural language, and perform well on a wide range of text-based tasks.</p>
<p>PaLM (2022) improved upon GPT-3 and other cutting-edge systems mostly by increasing the number of parameters and training on better hardware—without revolutionary new insights into the nature of human intelligence.</p>
<ul><li>PaLM improves upon the state-of-the-art in 28 of 29 tested NLP tasks.</li>
<li>PaLM is able, among other things, to explain an original joke in two-shot prompts.</li>
<li>In code generation, PaLM equals the performance of Codex 12B (which was fine-tuned on that task) while using 50 times less Python code.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
