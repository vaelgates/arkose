<div class="page-data" data-page-title="Why these systems might come soon"></div><ol><li>The story so far with AI development: We’ve been working on AI since ~1950s, in an era of history that feels normal to us but in fact develops technologies extremely quickly compared to most of human existence. In 2012, the deep learning revolution started with AlexNet and GPUs. Deep learning has made progress even faster than most fields of human endeavour: 10 years after AlexNet, we have unprecedented and unpredicted progress in large language model systems like GPT-3. These systems have unusual emergent capabilities (reading comprehension, translation, coding, math) considering they are just being trained on the next token of a language sequence. One can imagine that if we continue to pour in resources like training data and compute (as many companies are), continue to see algorithmic improvements at the rate we’ve seen, and continue to see hardware improvements, then maybe humanity will develop AI at very high levels of capabilities.<br/><br/>Even if we don’t see this progress with deep learning and need a paradigm shift, there’s still an immense amount of human investment being poured into AI in terms of talent, money from private investors + government + company profits, and resources. There’s international competition to develop AI fast, there’s immense economic incentives to make AI products that make our lives ever more convenient along with other benefits, and some of the leading companies (DeepMind, OpenAI) are explicitly aiming at AGI. Given that we’ve only been working on AI since the 1950s, and the major recent progress has been in the last 10 years, and the pace of technological innovation seems very fast or accelerating with worldwide investment, it seems likely we will alive at advanced AI someday, and that someday could be well within our lifetimes, absent major societal disruption.</li>
<li>More specifically:</li>
<ul><li>Significant investment into deep learning, with the involvement of GPUs and massive scaling, started around 2009. It's worth noting that we've been working on AI for less than 100 years and the current paradigm is around 10 years old, and that we've gotten pretty far in that time. However, some people think that we should be much further.</li>
<li>We haven’t worked on this for very long, with AI research starting in the 1950s and <a href='https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/' target='_blank'>investments increasing massively</a> since 2010.</li>
<li>Data from <a href='https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf' target='_blank'>PaLM</a>, the most compute intensive model ever trained at the time, suggests that improvements continue scaling well with model size even in the 500+ billion parameter range. New capabilities emerge just as a function of scale: For example, PaLM is able to explain novel jokes. It also surpassed previous, smaller models on 28 out of 29 widely-used NLP tasks.</li>
<li>Since then, the amount of compute invested into training large ML systems has increased tremndously - with a <a href='https://ar5iv.labs.arxiv.org/html/2202.05924' target='_blank'>5.7 month doubling time</a>. According to that paper, the growth rate for the largest models is somewhat slower, but still significantly faster than Moores Law would suggest, at 10.7 months.</li>
<li>Economic incentives and international competition motivates ongoing growth in investment.</li>
</ul><li>What experts think: AI Researcher Perceptions about timelines for advanced AI<br/>(While this is not an argument itself, it is interesting to consider the range of expert opinions)</li>
<ul><li>In a <a href='https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/#Summary_of_results' target='_blank'>2022 survey of AI researchers</a>, the aggregate forecasted time until human-level AI was 37 years (2059).</li>
<li>A <a href='https://www.cold-takes.com/are-we-trending-toward-transformative-ai-how-would-we-know/#surveying-experts' target='_blank'>survey from 2017</a> asked for ““when unaided machines can accomplish every task better and more cheaply than human workers" and got 20% probability by 2036, 50% by 2060, and 70% by 2100.</li>
<li>Here’s a <a href='https://docs.google.com/document/d/1j7tZ1Xf7-l2k2qr2t3MFwi-IkhXNdzA2N2WZBfcghsM/edit#heading=h.ozgth4xlf2qh' target='_blank'>document listing more timeline and risk predictions</a> - focussing mainly on expert surveys, but also including predictions using other frameworks.</li>
</ul><li>(Forecasting / Quantitative models / prediction frameworks) Forecasting predictions about advanced AI (example of forecasting, not about advanced AI: Again, this is not an argument in itself, but it is useful to consider. https://bounded-regret.ghost.io/ai-forecasting-one-year-in/ )</li>
<ul><li>The forecasting platform Metaculus estimates <a href='https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/' target='_blank'>the arrival of general AI in 2042</a>.</li>
<li>A <a href='https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines' target='_blank'>forecasting model</a> based on the amount of compute performed in biological systems estimated the year 2052, with a plausible range of 2040-2090. (<a href='https://www.cold-takes.com/forecasting-transformative-ai-the-biological-anchors-method-in-a-nutshell/' target='_blank'>more discussion including some criticism of that approach here</a>)</li>
</ul></ol><div>Further Reading:</div>
<ul><a href='https://docs.google.com/document/d/1j7tZ1Xf7-l2k2qr2t3MFwi-IkhXNdzA2N2WZBfcghsM/edit#' target='_blank'><li>A list of researcher surveys on AI timelines and risks</a></li>
<li>The AI Timelines post by Holden Karnofsky, blog series and podcast.</li>
</ul><div></div>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
<div>&#10149; <a href='the-alignment-problem'>OK, let’s move on - I want to learn about potential risks</a></div>
<div>&#9993; <a href='#feedback'>Send Feedback</a></div>
