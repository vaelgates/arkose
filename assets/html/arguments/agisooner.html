<div class="page-data" data-page-title="Why these systems might come soon"></div><ol><li>AI development so far: We’ve been working on AI since the 1950s. Though this era of history has felt normal to those living through it, in fact, technology has developed very quickly compared to most of human existence. In 2012, the deep learning revolution started with AlexNet and GPUs. Deep learning has made progress even faster than most fields of human endeavor: 10 years after AlexNet, we have unprecedented progress in large language model systems like GPT-3. These systems have unusual, emergent capabilities (such as reading comprehension, translation, coding, and math) given that these systems were trained to predict the next token of a language sequence. One can imagine that if we continue to pour in resources like training data and computational resources, as many companies are, we could continue to see algorithmic improvements at the rate we’ve seen previously. This progress, coupled with continued hardware improvements, may produce AI with remarkable capabilities.<br/><br/>Even if development of generally capable AI systems requires a paradigm shift above and beyond continued development of deep learning techniques, there’s still an immense amount of investment in the form of talent; money from private investors, governments, and private companies; and computational resources being dedicated to the development of these systems. There is an immense economic incentive to make AI products that make businesses more effective and consumers’ lives more convenient, and there is a great deal of international competition to develop AI quickly. Moreover, some leading AI companies, such as DeepMind and OpenAI, are explicitly aiming at AGI. Given that we’ve only been working on AI since the 1950s, that we have made major progress in the last 10 years, and the continuing rapid pace of technological innovation and worldwide investment, it seems likely we will arrive at advanced AI someday, and, absent major societal disruption, that day could be well within our lifetimes..</li>
<li>By the numbers:</li>
<ul><li>Significant investment into deep learning, with the involvement of GPUs and massive scaling, started around 2009. It's worth noting that we have been working on AI for less than 100 years and the current paradigm is around 10 years old, and that we have made significant progress in that time.</li>
<li>Some might say that AI is underperforming given that we have not achieved what many would call “true intelligence” yet. On the other hand, we have gotten large language models that seem to overperform compared to what they should be able to do.</li>
<li>We haven’t worked on this for very long, with AI research starting in the 1950s and <a href='https://venturebeat.com/ai/report-ai-investments-see-largest-year-over-year-growth-in-20-years/' target='_blank'>investments increasing massively</a> since 2010.</li>
<li>Data from <a href='https://storage.googleapis.com/pathways-language-model/PaLM-paper.pdf' target='_blank'>PaLM</a>, the most compute intensive model ever trained at the time, suggests that improvements continue scaling well with model size even in the 500+ billion parameter range. New capabilities emerge as a mere function of scale: For example, PaLM is able to explain novel jokes. PaLM also surpassed previous, smaller models on 28 out of 29 widely-used NLP tasks.</li>
<li>Since 2010, the amount of compute invested into training large ML systems has increased tremendously, with a <a href='https://arxiv.org/abs/2202.05924' target='_blank'>5.7 month doubling time</a>. The growth rate for the largest models is somewhat slower than that, but, at 10.7 months is still significantly faster than Moore's Law would predict.</li>
</ul><li>What experts think: AI Researcher Perceptions about timelines for advanced AI</li>
<ul><li>In a <a href='https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/#Summary_of_results' target='_blank'>2022 survey of AI researchers</a>, the aggregate forecasted time until human-level AI was 37 years (2059).</li>
<li>A <a href='https://www.cold-takes.com/are-we-trending-toward-transformative-ai-how-would-we-know/#surveying-experts' target='_blank'>survey from 2017</a> asked for ““when unaided machines can accomplish every task better and more cheaply than human workers" and got 20% probability by 2036, 50% by 2060, and 70% by 2100.</li>
<li>This <a href='https://docs.google.com/document/d/1j7tZ1Xf7-l2k2qr2t3MFwi-IkhXNdzA2N2WZBfcghsM/edit#heading=h.ozgth4xlf2qh' target='_blank'>document lists more timeline and risk predictions</a>. It mainly focuses on expert surveys, but also includes predictions using other frameworks.</li>
</ul><li>Forecasting / Quantitative models / prediction frameworks: Forecasting predictions about advanced AI (example of forecasting, not about advanced AI: Again, this is not an argument in itself, but it is useful to consider. https://bounded-regret.ghost.io/ai-forecasting-one-year-in/ )</li>
<ul><li>The forecasting platform Metaculus estimates <a href='https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/' target='_blank'>the arrival of general AI in 2042</a>.</li>
<li>A <a href='https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines' target='_blank'>forecasting model</a> based on the amount of compute performed in biological systems estimated the year 2052, with a plausible range of 2040-2090. (<a href='https://www.cold-takes.com/forecasting-transformative-ai-the-biological-anchors-method-in-a-nutshell/' target='_blank'>more discussion including some criticism of that approach here</a>)</li>
</ul></ol><p>Further Reading:</p>
<ul><a href='https://docs.google.com/document/d/1j7tZ1Xf7-l2k2qr2t3MFwi-IkhXNdzA2N2WZBfcghsM/edit#' target='_blank'><li>A list of researcher surveys on AI timelines and risks</a></li>
<li>The AI Timelines post by Holden Karnofsky, blog series and podcast.</li>
</ul><a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
