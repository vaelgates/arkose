<div class="page-data" data-page-title="Misuse is a bigger problem"></div>
<blockquote><p>
I guess like anything I see, there is a risk, just like any other tool, that this will be used for nefarious purposes, like automated systems that make decisions in a way that we don't quite understand. Then baking in of bias, whether we're talking about automated weapon systems that make decisions on closing the loop in deciding who to shoot to automated decisions and policing and things like that. 
<p class='interview-attribution'>&#40;from: <a href='../interviews'>Interviews with AI Researchers</a>&#41;</p></p></blockquote>

<p>Misuse continues to be a problem as we get more and more powerful systems. For example, it used to be impossible for a small number of people to cause incredible damage. But now that we’ve developed nuclear weapons, whoever is in control of those weapons has a huge amount of power to affect the world in a way that wasn’t true historically.</p>
<ul><li>You might argue that AI is similar, in that a small number of actors may have an outsized ability to affect the world because the development of cutting-edge AI is currently happening at just a small number of well-funded companies.</li>
<li>Alternatively, if it turns out that AGI is developed in a decentralized fashion, this will create misuse problems of its own, such as a “race to the bottom” where outcomes are determined by the most immoral, misinformed, or mentally ill group or individual to control an AGI.</li>
</ul><p>Humanity has dealt with misuse before. Misuse of technology has produced very undesirable outcomes in the past when leaders have directed an outsized amount of resources, and much attention should be focused on this.</p>
<p>However, we also want to pay attention to a more neglected risk that could potentially be even worse than misuse. AGI takes an aspect of humanity that has enabled us to shape most of our environment and become earth’s dominant species—intelligence—and amplifies it beyond human capabilities. This makes the danger from misaligned AGI potentially significantly higher than the danger from previous misuses of technology.</p>
<a name='argnav'/>
<br/><br/><br/><!-- temporary fix for issue 19 -->
